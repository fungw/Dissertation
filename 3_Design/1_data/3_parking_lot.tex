\pagebreak

\subsection{Dublin Parking Lot Data}\label{data:parking_lot}
Live Dublin parking lot data is publicly available through the \ac{DCC} website. Parking lot data is required to provide a realistic model on the occupancies of Dublin parking lots. The data is used to pad the spaces of parking lots in the simulation.

Scrapy is a Python crawler for extracting data from websites \citep{2017ScrapyCrawler}. A cronjob is a scheduler that allows computing tasks to be run at a specified time interval \citep{2017CronTabDocumentation}. A cronjob is set up for the crawler to scrape the live Dublin parking lot site every five minutes. The data is periodically saved to an SQLite database so that it can be extracted later on and used in the simulation. A subset of the parking lot data can be found in Appendix B.